{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea286b4c-ff4b-42f9-bfd2-2746a387aa32",
   "metadata": {},
   "source": [
    "### On its own (MLP1L) (Verification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d3c6d74-60b3-4d83-8f3a-1aaa3d319d53",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Results from Folder: ZC-CSA_images ===\n",
      " Index  True  Adversarial  Magnitude  ModelPred\n",
      "   102     2            7    1150.38          7\n",
      "   103     2            8    1133.78          8\n",
      "   104     2            7     852.70          7\n",
      "   107     2            7    1087.49          7\n",
      "   111     2            7    1155.91          7\n",
      "   114     2            7    1132.34          7\n",
      "   116     2            5    1152.05          5\n",
      "   118     2            7    1108.96          7\n",
      "    11     0            2    1138.52          2\n",
      "   120     2            7    1183.65          7\n",
      "   121     2            0    1138.58          0\n",
      "   123     2            8    1111.15          8\n",
      "   128     2            7    1124.17          7\n",
      "   139     2            3    1168.42          3\n",
      "    13     0            6    1126.73          6\n",
      "   141     2            6    1155.44          6\n",
      "   144     2            3     934.63          3\n",
      "   150     3            5    1166.40          5\n",
      "   153     3            5    1115.46          5\n",
      "   155     3            5    1165.49          5\n",
      "   158     3            5    1134.19          5\n",
      "   159     3            5    1185.14          5\n",
      "    15     0            2    1118.25          2\n",
      "   162     3            5    1147.49          5\n",
      "   163     3            5    1152.43          5\n",
      "   167     3            5    1125.65          5\n",
      "   168     3            2    1121.27          2\n",
      "   169     3            5    1149.45          5\n",
      "   171     3            8    1148.04          8\n",
      "   174     3            5    1190.89          5\n",
      "   176     3            5    1149.15          5\n",
      "   178     3            8    1138.91          8\n",
      "   179     3            5    1164.68          5\n",
      "   182     3            2    1156.65          2\n",
      "   185     3            2    1170.56          2\n",
      "   186     3            5    1144.06          5\n",
      "   192     3            2    1144.64          2\n",
      "   193     3            5    1155.70          5\n",
      "   194     3            5    1149.41          5\n",
      "     1     0            6     976.27          6\n",
      "   201     4            7    1162.73          7\n",
      "   202     4            7    1125.89          7\n",
      "   205     4            5    1136.09          5\n",
      "   206     4            7    1163.98          7\n",
      "   207     4            9    1175.66          9\n",
      "   208     4            7    1153.94          7\n",
      "   209     4            6    1122.29          6\n",
      "    20     0            2    1175.42          2\n",
      "   210     4            7    1150.17          7\n",
      "   211     4            2    1145.57          2\n",
      "   212     4            9    1155.34          9\n",
      "   213     4            6    1162.00          6\n",
      "   214     4            7    1132.09          7\n",
      "   215     4            2    1162.27          2\n",
      "   216     4            9    1170.82          9\n",
      "   217     4            5    1170.32          5\n",
      "    21     0            2    1145.01          2\n",
      "   220     4            7    1167.92          7\n",
      "   223     4            7    1130.14          7\n",
      "   224     4            8    1131.23          8\n",
      "   225     4            7    1157.92          7\n",
      "   226     4            7    1119.89          7\n",
      "   229     4            9    1166.41          9\n",
      "   230     4            9    1136.37          9\n",
      "   231     4            2    1162.65          2\n",
      "   232     4            7    1117.22          7\n",
      "   233     4            7    1192.69          7\n",
      "   234     4            2    1165.12          2\n",
      "   235     4            6    1173.18          6\n",
      "   236     4            5    1160.94          5\n",
      "   237     4            7    1138.88          7\n",
      "   238     4            7    1174.41          7\n",
      "   239     4            7    1123.75          7\n",
      "    23     0            2    1162.92          2\n",
      "   241     4            8    1142.41          8\n",
      "   242     4            7    1154.11          7\n",
      "   243     4            7    1148.52          7\n",
      "   244     4            7    1188.07          7\n",
      "   245     4            8    1165.13          8\n",
      "   246     4            9    1165.51          9\n",
      "   247     4            8    1125.75          8\n",
      "   248     4            2    1167.17          2\n",
      "   252     5            7    1147.16          7\n",
      "   253     5            7    1104.70          7\n",
      "   256     5            3    1168.67          3\n",
      "   258     5            2    1144.04          2\n",
      "   259     5            6    1143.67          6\n",
      "   260     5            3    1150.48          3\n",
      "   270     5            6    1132.26          6\n",
      "   275     5            6    1135.10          6\n",
      "   277     5            8    1131.08          8\n",
      "   281     5            3    1145.50          3\n",
      "   289     5            2    1193.98          2\n",
      "    28     0            7    1177.14          7\n",
      "   290     5            3    1124.30          3\n",
      "   291     5            3    1100.36          3\n",
      "   292     5            3    1111.12          3\n",
      "   293     5            3    1157.89          3\n",
      "   296     5            8    1143.71          8\n",
      "   297     5            8    1170.60          8\n",
      "   298     5            3    1087.68          3\n",
      "   299     5            6    1192.01          6\n",
      "   300     6            2    1160.63          2\n",
      "   301     6            2    1146.99          2\n",
      "   302     6            5    1210.13          5\n",
      "   303     6            0    1168.26          0\n",
      "   305     6            2    1157.49          2\n",
      "   306     6            2    1135.99          2\n",
      "   308     6            2    1181.27          2\n",
      "   313     6            2    1141.21          2\n",
      "   315     6            5    1164.16          5\n",
      "   316     6            5    1128.82          5\n",
      "   318     6            2    1163.08          2\n",
      "   319     6            2    1170.23          2\n",
      "   320     6            5    1173.41          5\n",
      "   323     6            2    1185.15          2\n",
      "   325     6            1    1146.30          1\n",
      "   326     6            2    1151.47          2\n",
      "   330     6            2    1155.90          2\n",
      "   333     6            0    1105.36          0\n",
      "   336     6            2    1170.17          2\n",
      "   337     6            0    1154.82          0\n",
      "   339     6            2    1152.74          2\n",
      "    33     0            2    1156.56          2\n",
      "   345     6            2    1148.59          2\n",
      "   346     6            7    1164.51          7\n",
      "   348     6            2    1148.06          2\n",
      "   350     7            5    1173.26          5\n",
      "   355     7            2    1162.93          2\n",
      "   356     7            2    1141.14          2\n",
      "   363     7            2    1172.50          2\n",
      "   365     7            2    1161.92          2\n",
      "    36     0            2    1180.60          2\n",
      "   370     7            2    1168.79          2\n",
      "   373     7            2    1126.99          2\n",
      "   374     7            2    1179.76          2\n",
      "   376     7            2    1160.42          2\n",
      "   378     7            2    1131.28          2\n",
      "    37     0            2    1149.64          2\n",
      "   380     7            2    1155.79          2\n",
      "   382     7            3    1148.60          3\n",
      "   389     7            5    1162.27          5\n",
      "    38     0            2    1172.94          2\n",
      "   390     7            2    1137.06          2\n",
      "   391     7            1    1179.68          1\n",
      "   392     7            2    1178.63          2\n",
      "   395     7            2    1153.24          2\n",
      "   396     7            2    1169.87          2\n",
      "     3     0            2    1172.68          2\n",
      "   400     8            5    1142.64          5\n",
      "   403     8            2    1167.28          2\n",
      "   404     8            5    1182.24          5\n",
      "   405     8            2    1165.11          2\n",
      "   406     8            5    1159.17          5\n",
      "   408     8            7    1168.58          7\n",
      "   409     8            9    1156.36          9\n",
      "    40     0            5    1159.55          5\n",
      "   410     8            2    1143.00          2\n",
      "   411     8            2    1189.78          2\n",
      "   412     8            3    1144.57          3\n",
      "   414     8            2    1138.69          2\n",
      "   415     8            5    1168.67          5\n",
      "   416     8            2    1127.65          2\n",
      "   417     8            3    1129.57          3\n",
      "   418     8            2    1164.63          2\n",
      "   419     8            2    1188.41          2\n",
      "    41     0            5    1177.04          5\n",
      "   420     8            5    1123.43          5\n",
      "   421     8            2    1147.26          2\n",
      "   423     8            3    1179.42          3\n",
      "   424     8            6    1140.94          6\n",
      "   425     8            3    1107.27          3\n",
      "   426     8            2    1163.29          2\n",
      "   427     8            2    1156.91          2\n",
      "   428     8            2    1147.20          2\n",
      "   430     8            2    1173.14          2\n",
      "   431     8            3    1171.69          3\n",
      "   433     8            2    1169.74          2\n",
      "   436     8            7    1180.17          7\n",
      "   438     8            2    1139.49          2\n",
      "   439     8            2    1109.50          2\n",
      "    43     0            2    1167.45          2\n",
      "   440     8            2    1138.61          2\n",
      "   441     8            2    1085.79          2\n",
      "   442     8            2    1155.72          2\n",
      "   443     8            2    1189.39          2\n",
      "   444     8            3    1152.65          3\n",
      "   445     8            2    1202.62          2\n",
      "   447     8            2    1181.89          2\n",
      "   448     8            2    1161.00          2\n",
      "   449     8            2    1121.40          2\n",
      "   450     9            7    1155.84          7\n",
      "   451     9            4    1135.22          4\n",
      "   452     9            7    1177.54          7\n",
      "   453     9            7    1155.67          7\n",
      "   454     9            3    1144.98          3\n",
      "   455     9            7    1203.38          7\n",
      "   456     9            7    1179.40          7\n",
      "   457     9            8    1177.60          8\n",
      "   458     9            5    1173.08          5\n",
      "   459     9            8    1157.64          8\n",
      "   460     9            5    1125.99          5\n",
      "   461     9            7    1166.63          7\n",
      "   462     9            7    1143.01          7\n",
      "   463     9            7    1141.03          7\n",
      "   464     9            0    1114.16          0\n",
      "   465     9            3    1220.33          3\n",
      "   466     9            7    1119.81          7\n",
      "   467     9            7    1112.88          7\n",
      "   468     9            7    1165.79          7\n",
      "   469     9            7    1136.68          7\n",
      "   470     9            7    1163.41          7\n",
      "   471     9            8    1154.87          8\n",
      "   472     9            5    1174.94          5\n",
      "   474     9            7    1121.94          7\n",
      "   475     9            7    1204.61          7\n",
      "   476     9            7    1178.97          7\n",
      "   477     9            7    1174.70          7\n",
      "   478     9            7    1142.58          7\n",
      "   479     9            7    1149.20          7\n",
      "   480     9            3    1146.35          3\n",
      "   481     9            7    1145.73          7\n",
      "   482     9            8    1154.24          8\n",
      "   483     9            2    1164.81          2\n",
      "   484     9            7    1108.08          7\n",
      "   485     9            8    1166.11          8\n",
      "   486     9            7    1126.27          7\n",
      "   487     9            7    1150.65          7\n",
      "   488     9            7    1135.62          7\n",
      "   489     9            7    1137.85          7\n",
      "   490     9            3    1161.21          3\n",
      "   491     9            7    1132.31          7\n",
      "   492     9            8    1155.54          8\n",
      "   493     9            2    1121.51          2\n",
      "   494     9            7    1160.17          7\n",
      "   495     9            7    1156.66          7\n",
      "   496     9            2    1168.47          2\n",
      "   497     9            5    1180.03          5\n",
      "   498     9            7    1198.83          7\n",
      "   499     9            7    1165.49          7\n",
      "    49     0            2    1135.87          2\n",
      "    50     1            2    1155.04          2\n",
      "    51     1            7    1172.88          7\n",
      "    52     1            2    1160.06          2\n",
      "    53     1            7    1208.24          7\n",
      "    54     1            2    1177.27          2\n",
      "    55     1            8    1176.34          8\n",
      "    56     1            2    1127.59          2\n",
      "    57     1            2    1159.94          2\n",
      "    58     1            3    1154.11          3\n",
      "    59     1            7    1201.36          7\n",
      "    60     1            2    1170.58          2\n",
      "    61     1            2    1181.28          2\n",
      "    62     1            7    1147.57          7\n",
      "    63     1            2    1176.07          2\n",
      "    64     1            2    1186.34          2\n",
      "    65     1            2    1163.00          2\n",
      "    66     1            2    1134.66          2\n",
      "    67     1            2    1187.51          2\n",
      "    68     1            2    1195.71          2\n",
      "    69     1            2    1155.91          2\n",
      "    70     1            8    1162.04          8\n",
      "    71     1            2    1166.64          2\n",
      "    72     1            2    1127.93          2\n",
      "    74     1            2    1154.73          2\n",
      "    75     1            2    1128.59          2\n",
      "    76     1            7    1137.71          7\n",
      "    79     1            2    1164.47          2\n",
      "     7     0            7    1192.85          7\n",
      "    80     1            5    1149.23          5\n",
      "    81     1            7    1124.09          7\n",
      "    82     1            2    1136.76          2\n",
      "    83     1            2    1148.79          2\n",
      "    84     1            2    1119.85          2\n",
      "    85     1            2    1121.29          2\n",
      "    86     1            2    1187.36          2\n",
      "    87     1            2    1117.62          2\n",
      "    88     1            7    1162.04          7\n",
      "    89     1            8    1167.26          8\n",
      "     8     0            2    1148.85          2\n",
      "    90     1            2    1156.10          2\n",
      "    91     1            2    1153.71          2\n",
      "    92     1            7    1167.65          7\n",
      "    93     1            7    1150.62          7\n",
      "    94     1            2    1148.85          2\n",
      "    95     1            2    1132.68          2\n",
      "    96     1            2    1174.57          2\n",
      "    97     1            7    1170.05          7\n",
      "    98     1            2    1179.12          2\n",
      "    99     1            7    1159.93          7\n",
      "\n",
      "✅ All formatted tables have been copied to the clipboard!\n",
      "\n",
      "=== Misclassification Summary by Folder ===\n",
      "ZC-CSA_images     290/ 290 misclassified   (100.00%)\n",
      "\n",
      "Overall misclassification rate:\n",
      "    290/290 samples   (100.00%)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import pyperclip\n",
    "from pathlib import Path\n",
    "from io import StringIO\n",
    "\n",
    "\n",
    "# Set up the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the model\n",
    "model = torch.jit.load(r'Models and Data splits\\MainModel_MLP1L.pt')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Root directory for your adversarial images\n",
    "adversarial_root = Path(r\"Generated Data\\ZC-CSA_images\\Adversarial\")\n",
    "\n",
    "# Gather all PNG files recursively\n",
    "all_image_paths = list(adversarial_root.rglob(\"*.png\"))\n",
    "\n",
    "# Dictionary to accumulate results by folder\n",
    "results_by_folder = {}\n",
    "\n",
    "for file_path in all_image_paths:\n",
    "    try:\n",
    "        # Read as grayscale\n",
    "        image = cv2.imread(str(file_path), cv2.IMREAD_GRAYSCALE)\n",
    "        if image is None:\n",
    "            print(f\"Warning: Could not load image {file_path}\")\n",
    "            continue\n",
    "\n",
    "        # Normalize and flatten\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        vector = image.flatten().reshape(1, -1)\n",
    "        input_tensor = torch.tensor(vector, dtype=torch.float32, device=device)\n",
    "\n",
    "        # Forward pass\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_tensor)\n",
    "        predicted = torch.argmax(outputs, dim=1).item()\n",
    "\n",
    "        # Determine context folder name (e.g. 'Adversarial' subfolder)\n",
    "        context_folder = file_path.parts[-3] if len(file_path.parts) >= 3 else \"UnknownFolder\"\n",
    "\n",
    "        # Parse filename: '495_t9_p2_m814.39'\n",
    "        fname = file_path.stem\n",
    "        parts = fname.split(\"_\")           # ['495', 't9', 'p2', 'm814.39'] :contentReference[oaicite:0]{index=0}\n",
    "\n",
    "        index      = int(parts[0])\n",
    "        true_label = int(parts[1].lstrip(\"t\"))  # strip leading 't' :contentReference[oaicite:1]{index=1}\n",
    "        pred_label = int(parts[2].lstrip(\"p\"))  # strip leading 'p'\n",
    "        magnitude  = float(parts[3].lstrip(\"m\"))  # strip leading 'm'\n",
    "\n",
    "        # Append to results\n",
    "        results_by_folder.setdefault(context_folder, []).append({\n",
    "            \"Index\":     index,\n",
    "            \"True\":      true_label,\n",
    "            \"Adversarial\": pred_label,\n",
    "            \"Magnitude\": magnitude,\n",
    "            \"ModelPred\": predicted\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "# Prepare and print/copy output tables\n",
    "output = StringIO()\n",
    "for folder, records in results_by_folder.items():\n",
    "    df = pd.DataFrame(records)\n",
    "    header = f\"\\n=== Results from Folder: {folder} ===\\n\"\n",
    "    table_str = df.to_string(index=False)\n",
    "    print(header + table_str)\n",
    "    output.write(header)\n",
    "    output.write(table_str + \"\\n\")\n",
    "\n",
    "# Copy everything to the clipboard\n",
    "pyperclip.copy(output.getvalue())\n",
    "print(\"\\n✅ All formatted tables have been copied to the clipboard!\")\n",
    "\n",
    "# --- Misclassification Summary ---\n",
    "# Per‐folder\n",
    "print(\"\\n=== Misclassification Summary by Folder ===\")\n",
    "total_all = 0\n",
    "mismatch_all = 0\n",
    "\n",
    "for folder, records in results_by_folder.items():\n",
    "    df = pd.DataFrame(records)\n",
    "    total    = len(df)\n",
    "    mismatches = (df[\"True\"] != df[\"ModelPred\"]).sum()\n",
    "    pct      = mismatches / total * 100\n",
    "    print(f\"{folder:15s}  {mismatches:4d}/{total:4d} misclassified   ({pct:5.2f}%)\")\n",
    "    total_all    += total\n",
    "    mismatch_all += mismatches\n",
    "\n",
    "# Overall\n",
    "pct_all = mismatch_all / total_all * 100 if total_all else 0.0\n",
    "print(\"\\nOverall misclassification rate:\")\n",
    "print(f\"    {mismatch_all}/{total_all} samples   ({pct_all:.2f}%)\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc0e633-6a2c-4e35-8cf0-49238d164448",
   "metadata": {},
   "source": [
    "### MLP with 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef91126b-7671-456e-a8c3-dff0a69f572d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Results from Folder: ZC-CSA_images ===\n",
      " Index  True  Adversarial  Magnitude  ModelPred\n",
      "   102     2            7    1150.38          2\n",
      "   103     2            8    1133.78          2\n",
      "   104     2            7     852.70          8\n",
      "   107     2            7    1087.49          2\n",
      "   111     2            7    1155.91          2\n",
      "   114     2            7    1132.34          2\n",
      "   116     2            5    1152.05          2\n",
      "   118     2            7    1108.96          7\n",
      "    11     0            2    1138.52          0\n",
      "   120     2            7    1183.65          2\n",
      "   121     2            0    1138.58          4\n",
      "   123     2            8    1111.15          2\n",
      "   128     2            7    1124.17          2\n",
      "   139     2            3    1168.42          3\n",
      "    13     0            6    1126.73          0\n",
      "   141     2            6    1155.44          2\n",
      "   144     2            3     934.63          2\n",
      "   150     3            5    1166.40          3\n",
      "   153     3            5    1115.46          3\n",
      "   155     3            5    1165.49          7\n",
      "   158     3            5    1134.19          3\n",
      "   159     3            5    1185.14          3\n",
      "    15     0            2    1118.25          0\n",
      "   162     3            5    1147.49          5\n",
      "   163     3            5    1152.43          5\n",
      "   167     3            5    1125.65          3\n",
      "   168     3            2    1121.27          2\n",
      "   169     3            5    1149.45          3\n",
      "   171     3            8    1148.04          8\n",
      "   174     3            5    1190.89          3\n",
      "   176     3            5    1149.15          3\n",
      "   178     3            8    1138.91          3\n",
      "   179     3            5    1164.68          3\n",
      "   182     3            2    1156.65          2\n",
      "   185     3            2    1170.56          3\n",
      "   186     3            5    1144.06          8\n",
      "   192     3            2    1144.64          3\n",
      "   193     3            5    1155.70          5\n",
      "   194     3            5    1149.41          5\n",
      "     1     0            6     976.27          0\n",
      "   201     4            7    1162.73          4\n",
      "   202     4            7    1125.89          4\n",
      "   205     4            5    1136.09          5\n",
      "   206     4            7    1163.98          4\n",
      "   207     4            9    1175.66          4\n",
      "   208     4            7    1153.94          4\n",
      "   209     4            6    1122.29          4\n",
      "    20     0            2    1175.42          0\n",
      "   210     4            7    1150.17          4\n",
      "   211     4            2    1145.57          4\n",
      "   212     4            9    1155.34          9\n",
      "   213     4            6    1162.00          4\n",
      "   214     4            7    1132.09          4\n",
      "   215     4            2    1162.27          4\n",
      "   216     4            9    1170.82          4\n",
      "   217     4            5    1170.32          4\n",
      "    21     0            2    1145.01          2\n",
      "   220     4            7    1167.92          8\n",
      "   223     4            7    1130.14          4\n",
      "   224     4            8    1131.23          4\n",
      "   225     4            7    1157.92          4\n",
      "   226     4            7    1119.89          4\n",
      "   229     4            9    1166.41          4\n",
      "   230     4            9    1136.37          4\n",
      "   231     4            2    1162.65          4\n",
      "   232     4            7    1117.22          4\n",
      "   233     4            7    1192.69          4\n",
      "   234     4            2    1165.12          7\n",
      "   235     4            6    1173.18          6\n",
      "   236     4            5    1160.94          5\n",
      "   237     4            7    1138.88          4\n",
      "   238     4            7    1174.41          7\n",
      "   239     4            7    1123.75          7\n",
      "    23     0            2    1162.92          0\n",
      "   241     4            8    1142.41          4\n",
      "   242     4            7    1154.11          4\n",
      "   243     4            7    1148.52          4\n",
      "   244     4            7    1188.07          4\n",
      "   245     4            8    1165.13          4\n",
      "   246     4            9    1165.51          4\n",
      "   247     4            8    1125.75          9\n",
      "   248     4            2    1167.17          4\n",
      "   252     5            7    1147.16          5\n",
      "   253     5            7    1104.70          5\n",
      "   256     5            3    1168.67          5\n",
      "   258     5            2    1144.04          5\n",
      "   259     5            6    1143.67          5\n",
      "   260     5            3    1150.48          3\n",
      "   270     5            6    1132.26          5\n",
      "   275     5            6    1135.10          5\n",
      "   277     5            8    1131.08          5\n",
      "   281     5            3    1145.50          5\n",
      "   289     5            2    1193.98          5\n",
      "    28     0            7    1177.14          0\n",
      "   290     5            3    1124.30          3\n",
      "   291     5            3    1100.36          5\n",
      "   292     5            3    1111.12          5\n",
      "   293     5            3    1157.89          5\n",
      "   296     5            8    1143.71          5\n",
      "   297     5            8    1170.60          5\n",
      "   298     5            3    1087.68          5\n",
      "   299     5            6    1192.01          5\n",
      "   300     6            2    1160.63          6\n",
      "   301     6            2    1146.99          6\n",
      "   302     6            5    1210.13          6\n",
      "   303     6            0    1168.26          0\n",
      "   305     6            2    1157.49          6\n",
      "   306     6            2    1135.99          6\n",
      "   308     6            2    1181.27          6\n",
      "   313     6            2    1141.21          6\n",
      "   315     6            5    1164.16          6\n",
      "   316     6            5    1128.82          6\n",
      "   318     6            2    1163.08          6\n",
      "   319     6            2    1170.23          2\n",
      "   320     6            5    1173.41          6\n",
      "   323     6            2    1185.15          2\n",
      "   325     6            1    1146.30          6\n",
      "   326     6            2    1151.47          6\n",
      "   330     6            2    1155.90          6\n",
      "   333     6            0    1105.36          6\n",
      "   336     6            2    1170.17          2\n",
      "   337     6            0    1154.82          6\n",
      "   339     6            2    1152.74          2\n",
      "    33     0            2    1156.56          0\n",
      "   345     6            2    1148.59          6\n",
      "   346     6            7    1164.51          6\n",
      "   348     6            2    1148.06          6\n",
      "   350     7            5    1173.26          5\n",
      "   355     7            2    1162.93          2\n",
      "   356     7            2    1141.14          2\n",
      "   363     7            2    1172.50          2\n",
      "   365     7            2    1161.92          2\n",
      "    36     0            2    1180.60          0\n",
      "   370     7            2    1168.79          3\n",
      "   373     7            2    1126.99          7\n",
      "   374     7            2    1179.76          2\n",
      "   376     7            2    1160.42          2\n",
      "   378     7            2    1131.28          7\n",
      "    37     0            2    1149.64          0\n",
      "   380     7            2    1155.79          7\n",
      "   382     7            3    1148.60          7\n",
      "   389     7            5    1162.27          7\n",
      "    38     0            2    1172.94          2\n",
      "   390     7            2    1137.06          7\n",
      "   391     7            1    1179.68          7\n",
      "   392     7            2    1178.63          2\n",
      "   395     7            2    1153.24          2\n",
      "   396     7            2    1169.87          7\n",
      "     3     0            2    1172.68          0\n",
      "   400     8            5    1142.64          2\n",
      "   403     8            2    1167.28          8\n",
      "   404     8            5    1182.24          3\n",
      "   405     8            2    1165.11          8\n",
      "   406     8            5    1159.17          8\n",
      "   408     8            7    1168.58          8\n",
      "   409     8            9    1156.36          8\n",
      "    40     0            5    1159.55          0\n",
      "   410     8            2    1143.00          8\n",
      "   411     8            2    1189.78          8\n",
      "   412     8            3    1144.57          8\n",
      "   414     8            2    1138.69          8\n",
      "   415     8            5    1168.67          8\n",
      "   416     8            2    1127.65          8\n",
      "   417     8            3    1129.57          8\n",
      "   418     8            2    1164.63          8\n",
      "   419     8            2    1188.41          8\n",
      "    41     0            5    1177.04          0\n",
      "   420     8            5    1123.43          8\n",
      "   421     8            2    1147.26          8\n",
      "   423     8            3    1179.42          8\n",
      "   424     8            6    1140.94          8\n",
      "   425     8            3    1107.27          8\n",
      "   426     8            2    1163.29          8\n",
      "   427     8            2    1156.91          8\n",
      "   428     8            2    1147.20          8\n",
      "   430     8            2    1173.14          8\n",
      "   431     8            3    1171.69          8\n",
      "   433     8            2    1169.74          8\n",
      "   436     8            7    1180.17          3\n",
      "   438     8            2    1139.49          8\n",
      "   439     8            2    1109.50          8\n",
      "    43     0            2    1167.45          0\n",
      "   440     8            2    1138.61          8\n",
      "   441     8            2    1085.79          8\n",
      "   442     8            2    1155.72          8\n",
      "   443     8            2    1189.39          2\n",
      "   444     8            3    1152.65          8\n",
      "   445     8            2    1202.62          8\n",
      "   447     8            2    1181.89          8\n",
      "   448     8            2    1161.00          8\n",
      "   449     8            2    1121.40          8\n",
      "   450     9            7    1155.84          9\n",
      "   451     9            4    1135.22          9\n",
      "   452     9            7    1177.54          9\n",
      "   453     9            7    1155.67          9\n",
      "   454     9            3    1144.98          9\n",
      "   455     9            7    1203.38          9\n",
      "   456     9            7    1179.40          9\n",
      "   457     9            8    1177.60          9\n",
      "   458     9            5    1173.08          9\n",
      "   459     9            8    1157.64          9\n",
      "   460     9            5    1125.99          5\n",
      "   461     9            7    1166.63          9\n",
      "   462     9            7    1143.01          9\n",
      "   463     9            7    1141.03          9\n",
      "   464     9            0    1114.16          9\n",
      "   465     9            3    1220.33          9\n",
      "   466     9            7    1119.81          9\n",
      "   467     9            7    1112.88          7\n",
      "   468     9            7    1165.79          9\n",
      "   469     9            7    1136.68          9\n",
      "   470     9            7    1163.41          9\n",
      "   471     9            8    1154.87          9\n",
      "   472     9            5    1174.94          9\n",
      "   474     9            7    1121.94          9\n",
      "   475     9            7    1204.61          9\n",
      "   476     9            7    1178.97          7\n",
      "   477     9            7    1174.70          9\n",
      "   478     9            7    1142.58          7\n",
      "   479     9            7    1149.20          9\n",
      "   480     9            3    1146.35          9\n",
      "   481     9            7    1145.73          9\n",
      "   482     9            8    1154.24          9\n",
      "   483     9            2    1164.81          3\n",
      "   484     9            7    1108.08          7\n",
      "   485     9            8    1166.11          9\n",
      "   486     9            7    1126.27          9\n",
      "   487     9            7    1150.65          9\n",
      "   488     9            7    1135.62          7\n",
      "   489     9            7    1137.85          9\n",
      "   490     9            3    1161.21          7\n",
      "   491     9            7    1132.31          9\n",
      "   492     9            8    1155.54          9\n",
      "   493     9            2    1121.51          9\n",
      "   494     9            7    1160.17          9\n",
      "   495     9            7    1156.66          9\n",
      "   496     9            2    1168.47          7\n",
      "   497     9            5    1180.03          8\n",
      "   498     9            7    1198.83          9\n",
      "   499     9            7    1165.49          7\n",
      "    49     0            2    1135.87          0\n",
      "    50     1            2    1155.04          1\n",
      "    51     1            7    1172.88          1\n",
      "    52     1            2    1160.06          1\n",
      "    53     1            7    1208.24          1\n",
      "    54     1            2    1177.27          1\n",
      "    55     1            8    1176.34          8\n",
      "    56     1            2    1127.59          1\n",
      "    57     1            2    1159.94          1\n",
      "    58     1            3    1154.11          1\n",
      "    59     1            7    1201.36          1\n",
      "    60     1            2    1170.58          1\n",
      "    61     1            2    1181.28          1\n",
      "    62     1            7    1147.57          1\n",
      "    63     1            2    1176.07          1\n",
      "    64     1            2    1186.34          1\n",
      "    65     1            2    1163.00          1\n",
      "    66     1            2    1134.66          1\n",
      "    67     1            2    1187.51          1\n",
      "    68     1            2    1195.71          1\n",
      "    69     1            2    1155.91          2\n",
      "    70     1            8    1162.04          1\n",
      "    71     1            2    1166.64          1\n",
      "    72     1            2    1127.93          1\n",
      "    74     1            2    1154.73          1\n",
      "    75     1            2    1128.59          1\n",
      "    76     1            7    1137.71          1\n",
      "    79     1            2    1164.47          1\n",
      "     7     0            7    1192.85          6\n",
      "    80     1            5    1149.23          5\n",
      "    81     1            7    1124.09          1\n",
      "    82     1            2    1136.76          2\n",
      "    83     1            2    1148.79          1\n",
      "    84     1            2    1119.85          1\n",
      "    85     1            2    1121.29          1\n",
      "    86     1            2    1187.36          1\n",
      "    87     1            2    1117.62          1\n",
      "    88     1            7    1162.04          1\n",
      "    89     1            8    1167.26          1\n",
      "     8     0            2    1148.85          0\n",
      "    90     1            2    1156.10          1\n",
      "    91     1            2    1153.71          1\n",
      "    92     1            7    1167.65          7\n",
      "    93     1            7    1150.62          1\n",
      "    94     1            2    1148.85          1\n",
      "    95     1            2    1132.68          1\n",
      "    96     1            2    1174.57          1\n",
      "    97     1            7    1170.05          1\n",
      "    98     1            2    1179.12          8\n",
      "    99     1            7    1159.93          1\n",
      "\n",
      "✅ All formatted tables have been copied to the clipboard!\n",
      "\n",
      "=== Misclassification Summary by Folder ===\n",
      "ZC-CSA_images      63/ 290 misclassified   (21.72%)\n",
      "\n",
      "Overall misclassification rate:\n",
      "    63/290 samples   (21.72%)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import pyperclip\n",
    "from pathlib import Path\n",
    "from io import StringIO\n",
    "\n",
    "\n",
    "# Set up the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the model\n",
    "model = torch.jit.load(r'Models and Data splits\\MLP2L.pt')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Root directory for your adversarial images\n",
    "adversarial_root = Path(r\"Generated Data\\ZC-CSA_images\\Adversarial\")\n",
    "\n",
    "# Gather all PNG files recursively\n",
    "all_image_paths = list(adversarial_root.rglob(\"*.png\"))\n",
    "\n",
    "# Dictionary to accumulate results by folder\n",
    "results_by_folder = {}\n",
    "\n",
    "for file_path in all_image_paths:\n",
    "    try:\n",
    "        # Read as grayscale\n",
    "        image = cv2.imread(str(file_path), cv2.IMREAD_GRAYSCALE)\n",
    "        if image is None:\n",
    "            print(f\"Warning: Could not load image {file_path}\")\n",
    "            continue\n",
    "\n",
    "        # Normalize and flatten\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        vector = image.flatten().reshape(1, -1)\n",
    "        input_tensor = torch.tensor(vector, dtype=torch.float32, device=device)\n",
    "\n",
    "        # Forward pass\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_tensor)\n",
    "        predicted = torch.argmax(outputs, dim=1).item()\n",
    "\n",
    "        # Determine context folder name (e.g. 'Adversarial' subfolder)\n",
    "        context_folder = file_path.parts[-3] if len(file_path.parts) >= 3 else \"UnknownFolder\"\n",
    "\n",
    "        # Parse filename: '495_t9_p2_m814.39'\n",
    "        fname = file_path.stem\n",
    "        parts = fname.split(\"_\")           # ['495', 't9', 'p2', 'm814.39'] :contentReference[oaicite:0]{index=0}\n",
    "\n",
    "        index      = int(parts[0])\n",
    "        true_label = int(parts[1].lstrip(\"t\"))  # strip leading 't' :contentReference[oaicite:1]{index=1}\n",
    "        pred_label = int(parts[2].lstrip(\"p\"))  # strip leading 'p'\n",
    "        magnitude  = float(parts[3].lstrip(\"m\"))  # strip leading 'm'\n",
    "\n",
    "        # Append to results\n",
    "        results_by_folder.setdefault(context_folder, []).append({\n",
    "            \"Index\":     index,\n",
    "            \"True\":      true_label,\n",
    "            \"Adversarial\": pred_label,\n",
    "            \"Magnitude\": magnitude,\n",
    "            \"ModelPred\": predicted\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "# Prepare and print/copy output tables\n",
    "output = StringIO()\n",
    "for folder, records in results_by_folder.items():\n",
    "    df = pd.DataFrame(records)\n",
    "    header = f\"\\n=== Results from Folder: {folder} ===\\n\"\n",
    "    table_str = df.to_string(index=False)\n",
    "    print(header + table_str)\n",
    "    output.write(header)\n",
    "    output.write(table_str + \"\\n\")\n",
    "\n",
    "# Copy everything to the clipboard\n",
    "pyperclip.copy(output.getvalue())\n",
    "print(\"\\n✅ All formatted tables have been copied to the clipboard!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Misclassification Summary ---\n",
    "# Per‐folder\n",
    "print(\"\\n=== Misclassification Summary by Folder ===\")\n",
    "total_all = 0\n",
    "mismatch_all = 0\n",
    "\n",
    "for folder, records in results_by_folder.items():\n",
    "    df = pd.DataFrame(records)\n",
    "    total    = len(df)\n",
    "    mismatches = (df[\"True\"] != df[\"ModelPred\"]).sum()\n",
    "    pct      = mismatches / total * 100\n",
    "    print(f\"{folder:15s}  {mismatches:4d}/{total:4d} misclassified   ({pct:5.2f}%)\")\n",
    "    total_all    += total\n",
    "    mismatch_all += mismatches\n",
    "\n",
    "# Overall\n",
    "pct_all = mismatch_all / total_all * 100 if total_all else 0.0\n",
    "print(\"\\nOverall misclassification rate:\")\n",
    "print(f\"    {mismatch_all}/{total_all} samples   ({pct_all:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467fd176-a716-40f1-a0a5-ea9cafac06f8",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8aebc0d9-c2e2-4e8c-8e2b-c62ae99a3479",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Results from Folder: ZC-CSA_images ===\n",
      " Index  True  Adversarial  Magnitude  ModelPred\n",
      "   102     2            7    1150.38          2\n",
      "   103     2            8    1133.78          2\n",
      "   104     2            7     852.70          2\n",
      "   107     2            7    1087.49          2\n",
      "   111     2            7    1155.91          2\n",
      "   114     2            7    1132.34          2\n",
      "   116     2            5    1152.05          2\n",
      "   118     2            7    1108.96          2\n",
      "    11     0            2    1138.52          0\n",
      "   120     2            7    1183.65          2\n",
      "   121     2            0    1138.58          2\n",
      "   123     2            8    1111.15          8\n",
      "   128     2            7    1124.17          2\n",
      "   139     2            3    1168.42          2\n",
      "    13     0            6    1126.73          6\n",
      "   141     2            6    1155.44          2\n",
      "   144     2            3     934.63          2\n",
      "   150     3            5    1166.40          3\n",
      "   153     3            5    1115.46          3\n",
      "   155     3            5    1165.49          3\n",
      "   158     3            5    1134.19          3\n",
      "   159     3            5    1185.14          3\n",
      "    15     0            2    1118.25          0\n",
      "   162     3            5    1147.49          3\n",
      "   163     3            5    1152.43          3\n",
      "   167     3            5    1125.65          3\n",
      "   168     3            2    1121.27          3\n",
      "   169     3            5    1149.45          3\n",
      "   171     3            8    1148.04          3\n",
      "   174     3            5    1190.89          3\n",
      "   176     3            5    1149.15          3\n",
      "   178     3            8    1138.91          3\n",
      "   179     3            5    1164.68          3\n",
      "   182     3            2    1156.65          3\n",
      "   185     3            2    1170.56          2\n",
      "   186     3            5    1144.06          3\n",
      "   192     3            2    1144.64          3\n",
      "   193     3            5    1155.70          3\n",
      "   194     3            5    1149.41          3\n",
      "     1     0            6     976.27          0\n",
      "   201     4            7    1162.73          4\n",
      "   202     4            7    1125.89          4\n",
      "   205     4            5    1136.09          4\n",
      "   206     4            7    1163.98          4\n",
      "   207     4            9    1175.66          4\n",
      "   208     4            7    1153.94          4\n",
      "   209     4            6    1122.29          4\n",
      "    20     0            2    1175.42          0\n",
      "   210     4            7    1150.17          4\n",
      "   211     4            2    1145.57          4\n",
      "   212     4            9    1155.34          4\n",
      "   213     4            6    1162.00          4\n",
      "   214     4            7    1132.09          4\n",
      "   215     4            2    1162.27          4\n",
      "   216     4            9    1170.82          4\n",
      "   217     4            5    1170.32          4\n",
      "    21     0            2    1145.01          0\n",
      "   220     4            7    1167.92          4\n",
      "   223     4            7    1130.14          4\n",
      "   224     4            8    1131.23          4\n",
      "   225     4            7    1157.92          4\n",
      "   226     4            7    1119.89          4\n",
      "   229     4            9    1166.41          4\n",
      "   230     4            9    1136.37          4\n",
      "   231     4            2    1162.65          4\n",
      "   232     4            7    1117.22          4\n",
      "   233     4            7    1192.69          4\n",
      "   234     4            2    1165.12          4\n",
      "   235     4            6    1173.18          4\n",
      "   236     4            5    1160.94          4\n",
      "   237     4            7    1138.88          4\n",
      "   238     4            7    1174.41          4\n",
      "   239     4            7    1123.75          4\n",
      "    23     0            2    1162.92          0\n",
      "   241     4            8    1142.41          4\n",
      "   242     4            7    1154.11          4\n",
      "   243     4            7    1148.52          4\n",
      "   244     4            7    1188.07          4\n",
      "   245     4            8    1165.13          4\n",
      "   246     4            9    1165.51          4\n",
      "   247     4            8    1125.75          4\n",
      "   248     4            2    1167.17          4\n",
      "   252     5            7    1147.16          5\n",
      "   253     5            7    1104.70          5\n",
      "   256     5            3    1168.67          5\n",
      "   258     5            2    1144.04          5\n",
      "   259     5            6    1143.67          5\n",
      "   260     5            3    1150.48          5\n",
      "   270     5            6    1132.26          5\n",
      "   275     5            6    1135.10          5\n",
      "   277     5            8    1131.08          5\n",
      "   281     5            3    1145.50          5\n",
      "   289     5            2    1193.98          5\n",
      "    28     0            7    1177.14          0\n",
      "   290     5            3    1124.30          5\n",
      "   291     5            3    1100.36          5\n",
      "   292     5            3    1111.12          5\n",
      "   293     5            3    1157.89          5\n",
      "   296     5            8    1143.71          5\n",
      "   297     5            8    1170.60          5\n",
      "   298     5            3    1087.68          5\n",
      "   299     5            6    1192.01          5\n",
      "   300     6            2    1160.63          6\n",
      "   301     6            2    1146.99          6\n",
      "   302     6            5    1210.13          6\n",
      "   303     6            0    1168.26          6\n",
      "   305     6            2    1157.49          6\n",
      "   306     6            2    1135.99          6\n",
      "   308     6            2    1181.27          6\n",
      "   313     6            2    1141.21          6\n",
      "   315     6            5    1164.16          6\n",
      "   316     6            5    1128.82          6\n",
      "   318     6            2    1163.08          6\n",
      "   319     6            2    1170.23          6\n",
      "   320     6            5    1173.41          6\n",
      "   323     6            2    1185.15          6\n",
      "   325     6            1    1146.30          6\n",
      "   326     6            2    1151.47          6\n",
      "   330     6            2    1155.90          6\n",
      "   333     6            0    1105.36          6\n",
      "   336     6            2    1170.17          6\n",
      "   337     6            0    1154.82          6\n",
      "   339     6            2    1152.74          6\n",
      "    33     0            2    1156.56          0\n",
      "   345     6            2    1148.59          6\n",
      "   346     6            7    1164.51          6\n",
      "   348     6            2    1148.06          6\n",
      "   350     7            5    1173.26          7\n",
      "   355     7            2    1162.93          7\n",
      "   356     7            2    1141.14          7\n",
      "   363     7            2    1172.50          7\n",
      "   365     7            2    1161.92          7\n",
      "    36     0            2    1180.60          0\n",
      "   370     7            2    1168.79          7\n",
      "   373     7            2    1126.99          7\n",
      "   374     7            2    1179.76          7\n",
      "   376     7            2    1160.42          7\n",
      "   378     7            2    1131.28          7\n",
      "    37     0            2    1149.64          0\n",
      "   380     7            2    1155.79          7\n",
      "   382     7            3    1148.60          7\n",
      "   389     7            5    1162.27          7\n",
      "    38     0            2    1172.94          0\n",
      "   390     7            2    1137.06          7\n",
      "   391     7            1    1179.68          7\n",
      "   392     7            2    1178.63          7\n",
      "   395     7            2    1153.24          7\n",
      "   396     7            2    1169.87          7\n",
      "     3     0            2    1172.68          0\n",
      "   400     8            5    1142.64          8\n",
      "   403     8            2    1167.28          8\n",
      "   404     8            5    1182.24          8\n",
      "   405     8            2    1165.11          8\n",
      "   406     8            5    1159.17          8\n",
      "   408     8            7    1168.58          8\n",
      "   409     8            9    1156.36          8\n",
      "    40     0            5    1159.55          0\n",
      "   410     8            2    1143.00          8\n",
      "   411     8            2    1189.78          8\n",
      "   412     8            3    1144.57          8\n",
      "   414     8            2    1138.69          8\n",
      "   415     8            5    1168.67          8\n",
      "   416     8            2    1127.65          8\n",
      "   417     8            3    1129.57          8\n",
      "   418     8            2    1164.63          8\n",
      "   419     8            2    1188.41          8\n",
      "    41     0            5    1177.04          0\n",
      "   420     8            5    1123.43          8\n",
      "   421     8            2    1147.26          8\n",
      "   423     8            3    1179.42          8\n",
      "   424     8            6    1140.94          0\n",
      "   425     8            3    1107.27          8\n",
      "   426     8            2    1163.29          8\n",
      "   427     8            2    1156.91          8\n",
      "   428     8            2    1147.20          8\n",
      "   430     8            2    1173.14          8\n",
      "   431     8            3    1171.69          8\n",
      "   433     8            2    1169.74          8\n",
      "   436     8            7    1180.17          8\n",
      "   438     8            2    1139.49          8\n",
      "   439     8            2    1109.50          8\n",
      "    43     0            2    1167.45          0\n",
      "   440     8            2    1138.61          8\n",
      "   441     8            2    1085.79          8\n",
      "   442     8            2    1155.72          8\n",
      "   443     8            2    1189.39          8\n",
      "   444     8            3    1152.65          8\n",
      "   445     8            2    1202.62          8\n",
      "   447     8            2    1181.89          8\n",
      "   448     8            2    1161.00          8\n",
      "   449     8            2    1121.40          8\n",
      "   450     9            7    1155.84          9\n",
      "   451     9            4    1135.22          9\n",
      "   452     9            7    1177.54          9\n",
      "   453     9            7    1155.67          9\n",
      "   454     9            3    1144.98          9\n",
      "   455     9            7    1203.38          9\n",
      "   456     9            7    1179.40          9\n",
      "   457     9            8    1177.60          9\n",
      "   458     9            5    1173.08          9\n",
      "   459     9            8    1157.64          9\n",
      "   460     9            5    1125.99          9\n",
      "   461     9            7    1166.63          9\n",
      "   462     9            7    1143.01          9\n",
      "   463     9            7    1141.03          9\n",
      "   464     9            0    1114.16          9\n",
      "   465     9            3    1220.33          9\n",
      "   466     9            7    1119.81          9\n",
      "   467     9            7    1112.88          9\n",
      "   468     9            7    1165.79          9\n",
      "   469     9            7    1136.68          9\n",
      "   470     9            7    1163.41          9\n",
      "   471     9            8    1154.87          9\n",
      "   472     9            5    1174.94          9\n",
      "   474     9            7    1121.94          9\n",
      "   475     9            7    1204.61          9\n",
      "   476     9            7    1178.97          9\n",
      "   477     9            7    1174.70          9\n",
      "   478     9            7    1142.58          9\n",
      "   479     9            7    1149.20          9\n",
      "   480     9            3    1146.35          9\n",
      "   481     9            7    1145.73          9\n",
      "   482     9            8    1154.24          9\n",
      "   483     9            2    1164.81          9\n",
      "   484     9            7    1108.08          9\n",
      "   485     9            8    1166.11          9\n",
      "   486     9            7    1126.27          9\n",
      "   487     9            7    1150.65          9\n",
      "   488     9            7    1135.62          9\n",
      "   489     9            7    1137.85          9\n",
      "   490     9            3    1161.21          9\n",
      "   491     9            7    1132.31          9\n",
      "   492     9            8    1155.54          9\n",
      "   493     9            2    1121.51          9\n",
      "   494     9            7    1160.17          9\n",
      "   495     9            7    1156.66          9\n",
      "   496     9            2    1168.47          9\n",
      "   497     9            5    1180.03          9\n",
      "   498     9            7    1198.83          9\n",
      "   499     9            7    1165.49          9\n",
      "    49     0            2    1135.87          0\n",
      "    50     1            2    1155.04          1\n",
      "    51     1            7    1172.88          1\n",
      "    52     1            2    1160.06          1\n",
      "    53     1            7    1208.24          1\n",
      "    54     1            2    1177.27          1\n",
      "    55     1            8    1176.34          1\n",
      "    56     1            2    1127.59          1\n",
      "    57     1            2    1159.94          1\n",
      "    58     1            3    1154.11          1\n",
      "    59     1            7    1201.36          1\n",
      "    60     1            2    1170.58          1\n",
      "    61     1            2    1181.28          1\n",
      "    62     1            7    1147.57          1\n",
      "    63     1            2    1176.07          1\n",
      "    64     1            2    1186.34          1\n",
      "    65     1            2    1163.00          1\n",
      "    66     1            2    1134.66          1\n",
      "    67     1            2    1187.51          1\n",
      "    68     1            2    1195.71          1\n",
      "    69     1            2    1155.91          1\n",
      "    70     1            8    1162.04          1\n",
      "    71     1            2    1166.64          1\n",
      "    72     1            2    1127.93          1\n",
      "    74     1            2    1154.73          1\n",
      "    75     1            2    1128.59          1\n",
      "    76     1            7    1137.71          1\n",
      "    79     1            2    1164.47          1\n",
      "     7     0            7    1192.85          0\n",
      "    80     1            5    1149.23          1\n",
      "    81     1            7    1124.09          1\n",
      "    82     1            2    1136.76          1\n",
      "    83     1            2    1148.79          1\n",
      "    84     1            2    1119.85          1\n",
      "    85     1            2    1121.29          1\n",
      "    86     1            2    1187.36          1\n",
      "    87     1            2    1117.62          1\n",
      "    88     1            7    1162.04          1\n",
      "    89     1            8    1167.26          1\n",
      "     8     0            2    1148.85          0\n",
      "    90     1            2    1156.10          1\n",
      "    91     1            2    1153.71          1\n",
      "    92     1            7    1167.65          1\n",
      "    93     1            7    1150.62          1\n",
      "    94     1            2    1148.85          1\n",
      "    95     1            2    1132.68          1\n",
      "    96     1            2    1174.57          1\n",
      "    97     1            7    1170.05          1\n",
      "    98     1            2    1179.12          1\n",
      "    99     1            7    1159.93          1\n",
      "\n",
      "✅ All formatted tables have been copied to the clipboard!\n",
      "\n",
      "=== Misclassification Summary by Folder ===\n",
      "ZC-CSA_images       4/ 290 misclassified   ( 1.38%)\n",
      "\n",
      "Overall misclassification rate:\n",
      "    4/290 samples   (1.38%)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import pyperclip\n",
    "from pathlib import Path\n",
    "from io import StringIO\n",
    "\n",
    "# 1. Setup device & load your saved CNN\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torch.jit.load(r\"Models and Data splits\\CNN.pt\").to(device)\n",
    "model.eval()\n",
    "\n",
    "# 2. Locate all adversarial PNGs\n",
    "adversarial_root = Path(r\"Generated Data\\ZC-CSA_images\\Adversarial\")\n",
    "all_image_paths = list(adversarial_root.rglob(\"*.png\"))\n",
    "\n",
    "results_by_folder = {}\n",
    "\n",
    "# 3. Inference loop\n",
    "for file_path in all_image_paths:\n",
    "    try:\n",
    "        # Load grayscale image\n",
    "        img = cv2.imread(str(file_path), cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Could not load image {file_path}\")\n",
    "            continue\n",
    "\n",
    "        # Normalize & reshape to (1,1,H,W)\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        tensor = torch.from_numpy(img).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        with torch.no_grad():\n",
    "            outputs = model(tensor)\n",
    "        predicted = outputs.argmax(dim=1).item()\n",
    "\n",
    "        # Determine folder context\n",
    "        context_folder = file_path.parts[-3] if len(file_path.parts) >= 3 else \"UnknownFolder\"\n",
    "\n",
    "        # Parse filename: e.g. \"495_t9_p2_m814.39.png\"\n",
    "        fname = file_path.stem\n",
    "        idx, t_lbl, p_lbl, m_val = fname.split(\"_\")\n",
    "        index      = int(idx)\n",
    "        true_label = int(t_lbl.lstrip(\"t\"))\n",
    "        pred_label = int(p_lbl.lstrip(\"p\"))\n",
    "        magnitude  = float(m_val.lstrip(\"m\"))\n",
    "\n",
    "        # Accumulate results\n",
    "        results_by_folder.setdefault(context_folder, []).append({\n",
    "            \"Index\":       index,\n",
    "            \"True\":        true_label,\n",
    "            \"Adversarial\": pred_label,\n",
    "            \"Magnitude\":   magnitude,\n",
    "            \"ModelPred\":   predicted\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "# 4. Print tables & copy to clipboard\n",
    "output = StringIO()\n",
    "for folder, records in results_by_folder.items():\n",
    "    df = pd.DataFrame(records)\n",
    "    header = f\"\\n=== Results from Folder: {folder} ===\\n\"\n",
    "    table_str = df.to_string(index=False)\n",
    "    print(header + table_str)\n",
    "    output.write(header)\n",
    "    output.write(table_str + \"\\n\")\n",
    "\n",
    "pyperclip.copy(output.getvalue())\n",
    "print(\"\\n✅ All formatted tables have been copied to the clipboard!\")\n",
    "\n",
    "\n",
    "\n",
    "# --- Misclassification Summary ---\n",
    "# Per‐folder\n",
    "print(\"\\n=== Misclassification Summary by Folder ===\")\n",
    "total_all = 0\n",
    "mismatch_all = 0\n",
    "\n",
    "for folder, records in results_by_folder.items():\n",
    "    df = pd.DataFrame(records)\n",
    "    total    = len(df)\n",
    "    mismatches = (df[\"True\"] != df[\"ModelPred\"]).sum()\n",
    "    pct      = mismatches / total * 100\n",
    "    print(f\"{folder:15s}  {mismatches:4d}/{total:4d} misclassified   ({pct:5.2f}%)\")\n",
    "    total_all    += total\n",
    "    mismatch_all += mismatches\n",
    "\n",
    "# Overall\n",
    "pct_all = mismatch_all / total_all * 100 if total_all else 0.0\n",
    "print(\"\\nOverall misclassification rate:\")\n",
    "print(f\"    {mismatch_all}/{total_all} samples   ({pct_all:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8874d6-d0b4-4522-976c-ed6643c81c67",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5c8323a-db95-41e3-ab2f-4383fd758aa4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Results from Folder: ZC-CSA_images ===\n",
      " Index  True  Adversarial  Magnitude  ModelPred\n",
      "   102     2            7    1150.38          4\n",
      "   103     2            8    1133.78          8\n",
      "   104     2            7     852.70          3\n",
      "   107     2            7    1087.49          2\n",
      "   111     2            7    1155.91          2\n",
      "   114     2            7    1132.34          2\n",
      "   116     2            5    1152.05          2\n",
      "   118     2            7    1108.96          2\n",
      "    11     0            2    1138.52          0\n",
      "   120     2            7    1183.65          2\n",
      "   121     2            0    1138.58          2\n",
      "   123     2            8    1111.15          8\n",
      "   128     2            7    1124.17          2\n",
      "   139     2            3    1168.42          3\n",
      "    13     0            6    1126.73          8\n",
      "   141     2            6    1155.44          2\n",
      "   144     2            3     934.63          3\n",
      "   150     3            5    1166.40          3\n",
      "   153     3            5    1115.46          3\n",
      "   155     3            5    1165.49          5\n",
      "   158     3            5    1134.19          5\n",
      "   159     3            5    1185.14          3\n",
      "    15     0            2    1118.25          0\n",
      "   162     3            5    1147.49          3\n",
      "   163     3            5    1152.43          3\n",
      "   167     3            5    1125.65          3\n",
      "   168     3            2    1121.27          2\n",
      "   169     3            5    1149.45          3\n",
      "   171     3            8    1148.04          3\n",
      "   174     3            5    1190.89          3\n",
      "   176     3            5    1149.15          3\n",
      "   178     3            8    1138.91          8\n",
      "   179     3            5    1164.68          3\n",
      "   182     3            2    1156.65          3\n",
      "   185     3            2    1170.56          3\n",
      "   186     3            5    1144.06          3\n",
      "   192     3            2    1144.64          3\n",
      "   193     3            5    1155.70          3\n",
      "   194     3            5    1149.41          3\n",
      "     1     0            6     976.27          0\n",
      "   201     4            7    1162.73          9\n",
      "   202     4            7    1125.89          4\n",
      "   205     4            5    1136.09          5\n",
      "   206     4            7    1163.98          4\n",
      "   207     4            9    1175.66          4\n",
      "   208     4            7    1153.94          4\n",
      "   209     4            6    1122.29          4\n",
      "    20     0            2    1175.42          0\n",
      "   210     4            7    1150.17          4\n",
      "   211     4            2    1145.57          4\n",
      "   212     4            9    1155.34          4\n",
      "   213     4            6    1162.00          4\n",
      "   214     4            7    1132.09          4\n",
      "   215     4            2    1162.27          4\n",
      "   216     4            9    1170.82          8\n",
      "   217     4            5    1170.32          4\n",
      "    21     0            2    1145.01          8\n",
      "   220     4            7    1167.92          4\n",
      "   223     4            7    1130.14          4\n",
      "   224     4            8    1131.23          4\n",
      "   225     4            7    1157.92          4\n",
      "   226     4            7    1119.89          8\n",
      "   229     4            9    1166.41          4\n",
      "   230     4            9    1136.37          3\n",
      "   231     4            2    1162.65          4\n",
      "   232     4            7    1117.22          4\n",
      "   233     4            7    1192.69          4\n",
      "   234     4            2    1165.12          8\n",
      "   235     4            6    1173.18          4\n",
      "   236     4            5    1160.94          5\n",
      "   237     4            7    1138.88          4\n",
      "   238     4            7    1174.41          4\n",
      "   239     4            7    1123.75          9\n",
      "    23     0            2    1162.92          0\n",
      "   241     4            8    1142.41          8\n",
      "   242     4            7    1154.11          4\n",
      "   243     4            7    1148.52          4\n",
      "   244     4            7    1188.07          4\n",
      "   245     4            8    1165.13          4\n",
      "   246     4            9    1165.51          4\n",
      "   247     4            8    1125.75          8\n",
      "   248     4            2    1167.17          4\n",
      "   252     5            7    1147.16          2\n",
      "   253     5            7    1104.70          5\n",
      "   256     5            3    1168.67          5\n",
      "   258     5            2    1144.04          5\n",
      "   259     5            6    1143.67          2\n",
      "   260     5            3    1150.48          3\n",
      "   270     5            6    1132.26          5\n",
      "   275     5            6    1135.10          6\n",
      "   277     5            8    1131.08          5\n",
      "   281     5            3    1145.50          5\n",
      "   289     5            2    1193.98          5\n",
      "    28     0            7    1177.14          0\n",
      "   290     5            3    1124.30          3\n",
      "   291     5            3    1100.36          5\n",
      "   292     5            3    1111.12          5\n",
      "   293     5            3    1157.89          3\n",
      "   296     5            8    1143.71          5\n",
      "   297     5            8    1170.60          8\n",
      "   298     5            3    1087.68          5\n",
      "   299     5            6    1192.01          8\n",
      "   300     6            2    1160.63          6\n",
      "   301     6            2    1146.99          6\n",
      "   302     6            5    1210.13          5\n",
      "   303     6            0    1168.26          6\n",
      "   305     6            2    1157.49          6\n",
      "   306     6            2    1135.99          6\n",
      "   308     6            2    1181.27          6\n",
      "   313     6            2    1141.21          6\n",
      "   315     6            5    1164.16          6\n",
      "   316     6            5    1128.82          6\n",
      "   318     6            2    1163.08          6\n",
      "   319     6            2    1170.23          2\n",
      "   320     6            5    1173.41          6\n",
      "   323     6            2    1185.15          6\n",
      "   325     6            1    1146.30          6\n",
      "   326     6            2    1151.47          6\n",
      "   330     6            2    1155.90          6\n",
      "   333     6            0    1105.36          6\n",
      "   336     6            2    1170.17          6\n",
      "   337     6            0    1154.82          2\n",
      "   339     6            2    1152.74          4\n",
      "    33     0            2    1156.56          0\n",
      "   345     6            2    1148.59          6\n",
      "   346     6            7    1164.51          2\n",
      "   348     6            2    1148.06          6\n",
      "   350     7            5    1173.26          9\n",
      "   355     7            2    1162.93          2\n",
      "   356     7            2    1141.14          2\n",
      "   363     7            2    1172.50          2\n",
      "   365     7            2    1161.92          2\n",
      "    36     0            2    1180.60          0\n",
      "   370     7            2    1168.79          8\n",
      "   373     7            2    1126.99          2\n",
      "   374     7            2    1179.76          2\n",
      "   376     7            2    1160.42          7\n",
      "   378     7            2    1131.28          8\n",
      "    37     0            2    1149.64          0\n",
      "   380     7            2    1155.79          2\n",
      "   382     7            3    1148.60          7\n",
      "   389     7            5    1162.27          7\n",
      "    38     0            2    1172.94          2\n",
      "   390     7            2    1137.06          7\n",
      "   391     7            1    1179.68          3\n",
      "   392     7            2    1178.63          7\n",
      "   395     7            2    1153.24          3\n",
      "   396     7            2    1169.87          8\n",
      "     3     0            2    1172.68          0\n",
      "   400     8            5    1142.64          8\n",
      "   403     8            2    1167.28          8\n",
      "   404     8            5    1182.24          0\n",
      "   405     8            2    1165.11          8\n",
      "   406     8            5    1159.17          8\n",
      "   408     8            7    1168.58          8\n",
      "   409     8            9    1156.36          8\n",
      "    40     0            5    1159.55          0\n",
      "   410     8            2    1143.00          8\n",
      "   411     8            2    1189.78          8\n",
      "   412     8            3    1144.57          8\n",
      "   414     8            2    1138.69          8\n",
      "   415     8            5    1168.67          8\n",
      "   416     8            2    1127.65          8\n",
      "   417     8            3    1129.57          8\n",
      "   418     8            2    1164.63          8\n",
      "   419     8            2    1188.41          8\n",
      "    41     0            5    1177.04          0\n",
      "   420     8            5    1123.43          8\n",
      "   421     8            2    1147.26          8\n",
      "   423     8            3    1179.42          8\n",
      "   424     8            6    1140.94          8\n",
      "   425     8            3    1107.27          8\n",
      "   426     8            2    1163.29          8\n",
      "   427     8            2    1156.91          8\n",
      "   428     8            2    1147.20          8\n",
      "   430     8            2    1173.14          8\n",
      "   431     8            3    1171.69          8\n",
      "   433     8            2    1169.74          8\n",
      "   436     8            7    1180.17          8\n",
      "   438     8            2    1139.49          8\n",
      "   439     8            2    1109.50          8\n",
      "    43     0            2    1167.45          0\n",
      "   440     8            2    1138.61          8\n",
      "   441     8            2    1085.79          8\n",
      "   442     8            2    1155.72          8\n",
      "   443     8            2    1189.39          2\n",
      "   444     8            3    1152.65          8\n",
      "   445     8            2    1202.62          8\n",
      "   447     8            2    1181.89          8\n",
      "   448     8            2    1161.00          8\n",
      "   449     8            2    1121.40          8\n",
      "   450     9            7    1155.84          9\n",
      "   451     9            4    1135.22          8\n",
      "   452     9            7    1177.54          4\n",
      "   453     9            7    1155.67          4\n",
      "   454     9            3    1144.98          8\n",
      "   455     9            7    1203.38          9\n",
      "   456     9            7    1179.40          9\n",
      "   457     9            8    1177.60          8\n",
      "   458     9            5    1173.08          9\n",
      "   459     9            8    1157.64          8\n",
      "   460     9            5    1125.99          9\n",
      "   461     9            7    1166.63          9\n",
      "   462     9            7    1143.01          9\n",
      "   463     9            7    1141.03          9\n",
      "   464     9            0    1114.16          9\n",
      "   465     9            3    1220.33          9\n",
      "   466     9            7    1119.81          9\n",
      "   467     9            7    1112.88          9\n",
      "   468     9            7    1165.79          5\n",
      "   469     9            7    1136.68          4\n",
      "   470     9            7    1163.41          9\n",
      "   471     9            8    1154.87          8\n",
      "   472     9            5    1174.94          9\n",
      "   474     9            7    1121.94          9\n",
      "   475     9            7    1204.61          9\n",
      "   476     9            7    1178.97          9\n",
      "   477     9            7    1174.70          8\n",
      "   478     9            7    1142.58          9\n",
      "   479     9            7    1149.20          9\n",
      "   480     9            3    1146.35          3\n",
      "   481     9            7    1145.73          9\n",
      "   482     9            8    1154.24          8\n",
      "   483     9            2    1164.81          8\n",
      "   484     9            7    1108.08          9\n",
      "   485     9            8    1166.11          8\n",
      "   486     9            7    1126.27          8\n",
      "   487     9            7    1150.65          4\n",
      "   488     9            7    1135.62          9\n",
      "   489     9            7    1137.85          9\n",
      "   490     9            3    1161.21          8\n",
      "   491     9            7    1132.31          5\n",
      "   492     9            8    1155.54          8\n",
      "   493     9            2    1121.51          8\n",
      "   494     9            7    1160.17          2\n",
      "   495     9            7    1156.66          9\n",
      "   496     9            2    1168.47          5\n",
      "   497     9            5    1180.03          9\n",
      "   498     9            7    1198.83          4\n",
      "   499     9            7    1165.49          3\n",
      "    49     0            2    1135.87          0\n",
      "    50     1            2    1155.04          2\n",
      "    51     1            7    1172.88          8\n",
      "    52     1            2    1160.06          2\n",
      "    53     1            7    1208.24          8\n",
      "    54     1            2    1177.27          5\n",
      "    55     1            8    1176.34          8\n",
      "    56     1            2    1127.59          2\n",
      "    57     1            2    1159.94          2\n",
      "    58     1            3    1154.11          3\n",
      "    59     1            7    1201.36          8\n",
      "    60     1            2    1170.58          8\n",
      "    61     1            2    1181.28          2\n",
      "    62     1            7    1147.57          2\n",
      "    63     1            2    1176.07          2\n",
      "    64     1            2    1186.34          2\n",
      "    65     1            2    1163.00          2\n",
      "    66     1            2    1134.66          2\n",
      "    67     1            2    1187.51          2\n",
      "    68     1            2    1195.71          2\n",
      "    69     1            2    1155.91          3\n",
      "    70     1            8    1162.04          8\n",
      "    71     1            2    1166.64          8\n",
      "    72     1            2    1127.93          8\n",
      "    74     1            2    1154.73          2\n",
      "    75     1            2    1128.59          8\n",
      "    76     1            7    1137.71          3\n",
      "    79     1            2    1164.47          2\n",
      "     7     0            7    1192.85          0\n",
      "    80     1            5    1149.23          6\n",
      "    81     1            7    1124.09          8\n",
      "    82     1            2    1136.76          2\n",
      "    83     1            2    1148.79          2\n",
      "    84     1            2    1119.85          2\n",
      "    85     1            2    1121.29          2\n",
      "    86     1            2    1187.36          3\n",
      "    87     1            2    1117.62          8\n",
      "    88     1            7    1162.04          8\n",
      "    89     1            8    1167.26          2\n",
      "     8     0            2    1148.85          0\n",
      "    90     1            2    1156.10          2\n",
      "    91     1            2    1153.71          2\n",
      "    92     1            7    1167.65          3\n",
      "    93     1            7    1150.62          2\n",
      "    94     1            2    1148.85          3\n",
      "    95     1            2    1132.68          2\n",
      "    96     1            2    1174.57          3\n",
      "    97     1            7    1170.05          6\n",
      "    98     1            2    1179.12          8\n",
      "    99     1            7    1159.93          8\n",
      "\n",
      "✅ All formatted tables have been copied to the clipboard!\n",
      "\n",
      "=== Misclassification Summary by Folder ===\n",
      "ZC-CSA_images     122/ 290 misclassified   (42.07%)\n",
      "\n",
      "Overall misclassification rate:\n",
      "    122/290 samples   (42.07%)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import pyperclip\n",
    "from pathlib import Path\n",
    "from io import StringIO\n",
    "\n",
    "# 1. Load your saved Random Forest model\n",
    "#    Adjust the path/filename to wherever you saved it with joblib.dump(...)\n",
    "rf_model = joblib.load(r\"Models and Data splits\\RF.pkl\")\n",
    "\n",
    "# 2. Locate all adversarial PNGs\n",
    "adversarial_root = Path(r\"Generated Data\\ZC-CSA_images\\Adversarial\")\n",
    "all_image_paths = list(adversarial_root.rglob(\"*.png\"))\n",
    "\n",
    "results_by_folder = {}\n",
    "\n",
    "# 3. Inference loop\n",
    "for file_path in all_image_paths:\n",
    "    try:\n",
    "        # Read as grayscale\n",
    "        img = cv2.imread(str(file_path), cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Could not load image {file_path}\")\n",
    "            continue\n",
    "\n",
    "        # Normalize pixel values to [0, 1], flatten to 1D feature vector\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        vector = img.flatten().reshape(1, -1)  # shape (1, n_features)\n",
    "\n",
    "        # Predict with your RF\n",
    "        pred = rf_model.predict(vector)[0]\n",
    "\n",
    "        # Determine folder context\n",
    "        context_folder = file_path.parts[-3] if len(file_path.parts) >= 3 else \"UnknownFolder\"\n",
    "\n",
    "        # Parse filename: e.g. \"495_t9_p2_m814.39.png\"\n",
    "        fname = file_path.stem\n",
    "        idx, t_lbl, p_lbl, m_val = fname.split(\"_\")\n",
    "        index      = int(idx)\n",
    "        true_label = int(t_lbl.lstrip(\"t\"))\n",
    "        pred_label = int(p_lbl.lstrip(\"p\"))\n",
    "        magnitude  = float(m_val.lstrip(\"m\"))\n",
    "\n",
    "        # Accumulate results\n",
    "        results_by_folder.setdefault(context_folder, []).append({\n",
    "            \"Index\":       index,\n",
    "            \"True\":        true_label,\n",
    "            \"Adversarial\": pred_label,\n",
    "            \"Magnitude\":   magnitude,\n",
    "            \"ModelPred\":   int(pred)\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "# 4. Prepare tables & copy to clipboard\n",
    "output = StringIO()\n",
    "for folder, records in results_by_folder.items():\n",
    "    df = pd.DataFrame(records)\n",
    "    header = f\"\\n=== Results from Folder: {folder} ===\\n\"\n",
    "    table_str = df.to_string(index=False)\n",
    "    print(header + table_str)\n",
    "    output.write(header)\n",
    "    output.write(table_str + \"\\n\")\n",
    "\n",
    "pyperclip.copy(output.getvalue())\n",
    "print(\"\\n✅ All formatted tables have been copied to the clipboard!\")\n",
    "\n",
    "\n",
    "\n",
    "# --- Misclassification Summary ---\n",
    "# Per‐folder\n",
    "print(\"\\n=== Misclassification Summary by Folder ===\")\n",
    "total_all = 0\n",
    "mismatch_all = 0\n",
    "\n",
    "for folder, records in results_by_folder.items():\n",
    "    df = pd.DataFrame(records)\n",
    "    total    = len(df)\n",
    "    mismatches = (df[\"True\"] != df[\"ModelPred\"]).sum()\n",
    "    pct      = mismatches / total * 100\n",
    "    print(f\"{folder:15s}  {mismatches:4d}/{total:4d} misclassified   ({pct:5.2f}%)\")\n",
    "    total_all    += total\n",
    "    mismatch_all += mismatches\n",
    "\n",
    "# Overall\n",
    "pct_all = mismatch_all / total_all * 100 if total_all else 0.0\n",
    "print(\"\\nOverall misclassification rate:\")\n",
    "print(f\"    {mismatch_all}/{total_all} samples   ({pct_all:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6348cef-0b6d-4385-a5b3-75dce86cd590",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c84cb6c-9617-4434-a84a-ca1bf762f866",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Results from Folder: ZC-CSA_images ===\n",
      " Index  True  Adversarial  Magnitude  ModelPred\n",
      "   102     2            7    1150.38          2\n",
      "   103     2            8    1133.78          2\n",
      "   104     2            7     852.70          7\n",
      "   107     2            7    1087.49          2\n",
      "   111     2            7    1155.91          2\n",
      "   114     2            7    1132.34          2\n",
      "   116     2            5    1152.05          2\n",
      "   118     2            7    1108.96          2\n",
      "    11     0            2    1138.52          0\n",
      "   120     2            7    1183.65          2\n",
      "   121     2            0    1138.58          2\n",
      "   123     2            8    1111.15          7\n",
      "   128     2            7    1124.17          2\n",
      "   139     2            3    1168.42          2\n",
      "    13     0            6    1126.73          0\n",
      "   141     2            6    1155.44          2\n",
      "   144     2            3     934.63          2\n",
      "   150     3            5    1166.40          3\n",
      "   153     3            5    1115.46          3\n",
      "   155     3            5    1165.49          9\n",
      "   158     3            5    1134.19          3\n",
      "   159     3            5    1185.14          3\n",
      "    15     0            2    1118.25          0\n",
      "   162     3            5    1147.49          5\n",
      "   163     3            5    1152.43          3\n",
      "   167     3            5    1125.65          3\n",
      "   168     3            2    1121.27          2\n",
      "   169     3            5    1149.45          3\n",
      "   171     3            8    1148.04          3\n",
      "   174     3            5    1190.89          3\n",
      "   176     3            5    1149.15          3\n",
      "   178     3            8    1138.91          3\n",
      "   179     3            5    1164.68          3\n",
      "   182     3            2    1156.65          3\n",
      "   185     3            2    1170.56          3\n",
      "   186     3            5    1144.06          3\n",
      "   192     3            2    1144.64          3\n",
      "   193     3            5    1155.70          3\n",
      "   194     3            5    1149.41          3\n",
      "     1     0            6     976.27          0\n",
      "   201     4            7    1162.73          4\n",
      "   202     4            7    1125.89          4\n",
      "   205     4            5    1136.09          4\n",
      "   206     4            7    1163.98          4\n",
      "   207     4            9    1175.66          4\n",
      "   208     4            7    1153.94          4\n",
      "   209     4            6    1122.29          4\n",
      "    20     0            2    1175.42          0\n",
      "   210     4            7    1150.17          4\n",
      "   211     4            2    1145.57          4\n",
      "   212     4            9    1155.34          4\n",
      "   213     4            6    1162.00          4\n",
      "   214     4            7    1132.09          4\n",
      "   215     4            2    1162.27          4\n",
      "   216     4            9    1170.82          4\n",
      "   217     4            5    1170.32          4\n",
      "    21     0            2    1145.01          0\n",
      "   220     4            7    1167.92          4\n",
      "   223     4            7    1130.14          4\n",
      "   224     4            8    1131.23          4\n",
      "   225     4            7    1157.92          4\n",
      "   226     4            7    1119.89          4\n",
      "   229     4            9    1166.41          4\n",
      "   230     4            9    1136.37          4\n",
      "   231     4            2    1162.65          4\n",
      "   232     4            7    1117.22          4\n",
      "   233     4            7    1192.69          4\n",
      "   234     4            2    1165.12          9\n",
      "   235     4            6    1173.18          4\n",
      "   236     4            5    1160.94          4\n",
      "   237     4            7    1138.88          4\n",
      "   238     4            7    1174.41          4\n",
      "   239     4            7    1123.75          4\n",
      "    23     0            2    1162.92          0\n",
      "   241     4            8    1142.41          4\n",
      "   242     4            7    1154.11          4\n",
      "   243     4            7    1148.52          4\n",
      "   244     4            7    1188.07          4\n",
      "   245     4            8    1165.13          4\n",
      "   246     4            9    1165.51          4\n",
      "   247     4            8    1125.75          4\n",
      "   248     4            2    1167.17          4\n",
      "   252     5            7    1147.16          5\n",
      "   253     5            7    1104.70          5\n",
      "   256     5            3    1168.67          5\n",
      "   258     5            2    1144.04          5\n",
      "   259     5            6    1143.67          5\n",
      "   260     5            3    1150.48          5\n",
      "   270     5            6    1132.26          5\n",
      "   275     5            6    1135.10          5\n",
      "   277     5            8    1131.08          5\n",
      "   281     5            3    1145.50          5\n",
      "   289     5            2    1193.98          5\n",
      "    28     0            7    1177.14          0\n",
      "   290     5            3    1124.30          5\n",
      "   291     5            3    1100.36          5\n",
      "   292     5            3    1111.12          5\n",
      "   293     5            3    1157.89          5\n",
      "   296     5            8    1143.71          5\n",
      "   297     5            8    1170.60          5\n",
      "   298     5            3    1087.68          5\n",
      "   299     5            6    1192.01          5\n",
      "   300     6            2    1160.63          6\n",
      "   301     6            2    1146.99          6\n",
      "   302     6            5    1210.13          6\n",
      "   303     6            0    1168.26          6\n",
      "   305     6            2    1157.49          6\n",
      "   306     6            2    1135.99          6\n",
      "   308     6            2    1181.27          6\n",
      "   313     6            2    1141.21          6\n",
      "   315     6            5    1164.16          6\n",
      "   316     6            5    1128.82          6\n",
      "   318     6            2    1163.08          6\n",
      "   319     6            2    1170.23          6\n",
      "   320     6            5    1173.41          6\n",
      "   323     6            2    1185.15          6\n",
      "   325     6            1    1146.30          6\n",
      "   326     6            2    1151.47          6\n",
      "   330     6            2    1155.90          6\n",
      "   333     6            0    1105.36          6\n",
      "   336     6            2    1170.17          6\n",
      "   337     6            0    1154.82          6\n",
      "   339     6            2    1152.74          6\n",
      "    33     0            2    1156.56          0\n",
      "   345     6            2    1148.59          6\n",
      "   346     6            7    1164.51          6\n",
      "   348     6            2    1148.06          6\n",
      "   350     7            5    1173.26          7\n",
      "   355     7            2    1162.93          7\n",
      "   356     7            2    1141.14          7\n",
      "   363     7            2    1172.50          7\n",
      "   365     7            2    1161.92          7\n",
      "    36     0            2    1180.60          0\n",
      "   370     7            2    1168.79          7\n",
      "   373     7            2    1126.99          1\n",
      "   374     7            2    1179.76          1\n",
      "   376     7            2    1160.42          7\n",
      "   378     7            2    1131.28          7\n",
      "    37     0            2    1149.64          0\n",
      "   380     7            2    1155.79          7\n",
      "   382     7            3    1148.60          7\n",
      "   389     7            5    1162.27          7\n",
      "    38     0            2    1172.94          0\n",
      "   390     7            2    1137.06          7\n",
      "   391     7            1    1179.68          7\n",
      "   392     7            2    1178.63          7\n",
      "   395     7            2    1153.24          7\n",
      "   396     7            2    1169.87          7\n",
      "     3     0            2    1172.68          0\n",
      "   400     8            5    1142.64          8\n",
      "   403     8            2    1167.28          8\n",
      "   404     8            5    1182.24          3\n",
      "   405     8            2    1165.11          8\n",
      "   406     8            5    1159.17          8\n",
      "   408     8            7    1168.58          8\n",
      "   409     8            9    1156.36          8\n",
      "    40     0            5    1159.55          0\n",
      "   410     8            2    1143.00          8\n",
      "   411     8            2    1189.78          8\n",
      "   412     8            3    1144.57          8\n",
      "   414     8            2    1138.69          8\n",
      "   415     8            5    1168.67          8\n",
      "   416     8            2    1127.65          8\n",
      "   417     8            3    1129.57          8\n",
      "   418     8            2    1164.63          8\n",
      "   419     8            2    1188.41          8\n",
      "    41     0            5    1177.04          0\n",
      "   420     8            5    1123.43          8\n",
      "   421     8            2    1147.26          8\n",
      "   423     8            3    1179.42          8\n",
      "   424     8            6    1140.94          0\n",
      "   425     8            3    1107.27          8\n",
      "   426     8            2    1163.29          8\n",
      "   427     8            2    1156.91          8\n",
      "   428     8            2    1147.20          8\n",
      "   430     8            2    1173.14          8\n",
      "   431     8            3    1171.69          8\n",
      "   433     8            2    1169.74          8\n",
      "   436     8            7    1180.17          8\n",
      "   438     8            2    1139.49          3\n",
      "   439     8            2    1109.50          8\n",
      "    43     0            2    1167.45          0\n",
      "   440     8            2    1138.61          8\n",
      "   441     8            2    1085.79          8\n",
      "   442     8            2    1155.72          8\n",
      "   443     8            2    1189.39          6\n",
      "   444     8            3    1152.65          8\n",
      "   445     8            2    1202.62          8\n",
      "   447     8            2    1181.89          8\n",
      "   448     8            2    1161.00          8\n",
      "   449     8            2    1121.40          8\n",
      "   450     9            7    1155.84          9\n",
      "   451     9            4    1135.22          9\n",
      "   452     9            7    1177.54          9\n",
      "   453     9            7    1155.67          9\n",
      "   454     9            3    1144.98          3\n",
      "   455     9            7    1203.38          9\n",
      "   456     9            7    1179.40          9\n",
      "   457     9            8    1177.60          9\n",
      "   458     9            5    1173.08          9\n",
      "   459     9            8    1157.64          9\n",
      "   460     9            5    1125.99          9\n",
      "   461     9            7    1166.63          9\n",
      "   462     9            7    1143.01          9\n",
      "   463     9            7    1141.03          9\n",
      "   464     9            0    1114.16          9\n",
      "   465     9            3    1220.33          9\n",
      "   466     9            7    1119.81          9\n",
      "   467     9            7    1112.88          9\n",
      "   468     9            7    1165.79          9\n",
      "   469     9            7    1136.68          9\n",
      "   470     9            7    1163.41          9\n",
      "   471     9            8    1154.87          9\n",
      "   472     9            5    1174.94          9\n",
      "   474     9            7    1121.94          9\n",
      "   475     9            7    1204.61          9\n",
      "   476     9            7    1178.97          9\n",
      "   477     9            7    1174.70          9\n",
      "   478     9            7    1142.58          9\n",
      "   479     9            7    1149.20          9\n",
      "   480     9            3    1146.35          9\n",
      "   481     9            7    1145.73          9\n",
      "   482     9            8    1154.24          9\n",
      "   483     9            2    1164.81          9\n",
      "   484     9            7    1108.08          9\n",
      "   485     9            8    1166.11          9\n",
      "   486     9            7    1126.27          9\n",
      "   487     9            7    1150.65          9\n",
      "   488     9            7    1135.62          9\n",
      "   489     9            7    1137.85          9\n",
      "   490     9            3    1161.21          9\n",
      "   491     9            7    1132.31          9\n",
      "   492     9            8    1155.54          9\n",
      "   493     9            2    1121.51          9\n",
      "   494     9            7    1160.17          9\n",
      "   495     9            7    1156.66          9\n",
      "   496     9            2    1168.47          1\n",
      "   497     9            5    1180.03          9\n",
      "   498     9            7    1198.83          9\n",
      "   499     9            7    1165.49          9\n",
      "    49     0            2    1135.87          0\n",
      "    50     1            2    1155.04          1\n",
      "    51     1            7    1172.88          1\n",
      "    52     1            2    1160.06          1\n",
      "    53     1            7    1208.24          1\n",
      "    54     1            2    1177.27          1\n",
      "    55     1            8    1176.34          1\n",
      "    56     1            2    1127.59          1\n",
      "    57     1            2    1159.94          1\n",
      "    58     1            3    1154.11          1\n",
      "    59     1            7    1201.36          1\n",
      "    60     1            2    1170.58          1\n",
      "    61     1            2    1181.28          1\n",
      "    62     1            7    1147.57          1\n",
      "    63     1            2    1176.07          1\n",
      "    64     1            2    1186.34          1\n",
      "    65     1            2    1163.00          1\n",
      "    66     1            2    1134.66          1\n",
      "    67     1            2    1187.51          1\n",
      "    68     1            2    1195.71          1\n",
      "    69     1            2    1155.91          7\n",
      "    70     1            8    1162.04          1\n",
      "    71     1            2    1166.64          1\n",
      "    72     1            2    1127.93          1\n",
      "    74     1            2    1154.73          1\n",
      "    75     1            2    1128.59          1\n",
      "    76     1            7    1137.71          1\n",
      "    79     1            2    1164.47          1\n",
      "     7     0            7    1192.85          0\n",
      "    80     1            5    1149.23          1\n",
      "    81     1            7    1124.09          1\n",
      "    82     1            2    1136.76          1\n",
      "    83     1            2    1148.79          1\n",
      "    84     1            2    1119.85          1\n",
      "    85     1            2    1121.29          1\n",
      "    86     1            2    1187.36          1\n",
      "    87     1            2    1117.62          1\n",
      "    88     1            7    1162.04          1\n",
      "    89     1            8    1167.26          1\n",
      "     8     0            2    1148.85          0\n",
      "    90     1            2    1156.10          1\n",
      "    91     1            2    1153.71          1\n",
      "    92     1            7    1167.65          1\n",
      "    93     1            7    1150.62          1\n",
      "    94     1            2    1148.85          1\n",
      "    95     1            2    1132.68          1\n",
      "    96     1            2    1174.57          1\n",
      "    97     1            7    1170.05          1\n",
      "    98     1            2    1179.12          1\n",
      "    99     1            7    1159.93          1\n",
      "\n",
      "✅ All formatted tables have been copied to the clipboard!\n",
      "\n",
      "=== Misclassification Summary by Folder ===\n",
      "ZC-CSA_images      15/ 290 misclassified   ( 5.17%)\n",
      "\n",
      "Overall misclassification rate:\n",
      "    15/290 samples   (5.17%)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import pyperclip\n",
    "from pathlib import Path\n",
    "from io import StringIO\n",
    "\n",
    "# 1. Load your saved Random Forest model\n",
    "#    Adjust the path/filename to wherever you saved it with joblib.dump(...)\n",
    "rf_model = joblib.load(r\"Models and Data splits\\kNN.pkl\")\n",
    "\n",
    "# 2. Locate all adversarial PNGs\n",
    "adversarial_root = Path(r\"Generated Data\\ZC-CSA_images\\Adversarial\")\n",
    "all_image_paths = list(adversarial_root.rglob(\"*.png\"))\n",
    "\n",
    "results_by_folder = {}\n",
    "\n",
    "# 3. Inference loop\n",
    "for file_path in all_image_paths:\n",
    "    try:\n",
    "        # Read as grayscale\n",
    "        img = cv2.imread(str(file_path), cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Could not load image {file_path}\")\n",
    "            continue\n",
    "\n",
    "        # Normalize pixel values to [0, 1], flatten to 1D feature vector\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        vector = img.flatten().reshape(1, -1)  # shape (1, n_features)\n",
    "\n",
    "        # Predict with your RF\n",
    "        pred = rf_model.predict(vector)[0]\n",
    "\n",
    "        # Determine folder context\n",
    "        context_folder = file_path.parts[-3] if len(file_path.parts) >= 3 else \"UnknownFolder\"\n",
    "\n",
    "        # Parse filename: e.g. \"495_t9_p2_m814.39.png\"\n",
    "        fname = file_path.stem\n",
    "        idx, t_lbl, p_lbl, m_val = fname.split(\"_\")\n",
    "        index      = int(idx)\n",
    "        true_label = int(t_lbl.lstrip(\"t\"))\n",
    "        pred_label = int(p_lbl.lstrip(\"p\"))\n",
    "        magnitude  = float(m_val.lstrip(\"m\"))\n",
    "\n",
    "        # Accumulate results\n",
    "        results_by_folder.setdefault(context_folder, []).append({\n",
    "            \"Index\":       index,\n",
    "            \"True\":        true_label,\n",
    "            \"Adversarial\": pred_label,\n",
    "            \"Magnitude\":   magnitude,\n",
    "            \"ModelPred\":   int(pred)\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "# 4. Prepare tables & copy to clipboard\n",
    "output = StringIO()\n",
    "for folder, records in results_by_folder.items():\n",
    "    df = pd.DataFrame(records)\n",
    "    header = f\"\\n=== Results from Folder: {folder} ===\\n\"\n",
    "    table_str = df.to_string(index=False)\n",
    "    print(header + table_str)\n",
    "    output.write(header)\n",
    "    output.write(table_str + \"\\n\")\n",
    "\n",
    "pyperclip.copy(output.getvalue())\n",
    "print(\"\\n✅ All formatted tables have been copied to the clipboard!\")\n",
    "\n",
    "\n",
    "\n",
    "# --- Misclassification Summary ---\n",
    "# Per‐folder\n",
    "print(\"\\n=== Misclassification Summary by Folder ===\")\n",
    "total_all = 0\n",
    "mismatch_all = 0\n",
    "\n",
    "for folder, records in results_by_folder.items():\n",
    "    df = pd.DataFrame(records)\n",
    "    total    = len(df)\n",
    "    mismatches = (df[\"True\"] != df[\"ModelPred\"]).sum()\n",
    "    pct      = mismatches / total * 100\n",
    "    print(f\"{folder:15s}  {mismatches:4d}/{total:4d} misclassified   ({pct:5.2f}%)\")\n",
    "    total_all    += total\n",
    "    mismatch_all += mismatches\n",
    "\n",
    "# Overall\n",
    "pct_all = mismatch_all / total_all * 100 if total_all else 0.0\n",
    "print(\"\\nOverall misclassification rate:\")\n",
    "print(f\"    {mismatch_all}/{total_all} samples   ({pct_all:.2f}%)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:GPUEnabled]",
   "language": "python",
   "name": "conda-env-GPUEnabled-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
